= 2024년 3분기 07월-09월 LWIL(Last week I learnt) 모음
// Metadata:
:description: Last Week I Learnt
:keywords: study, til, lwil
// Settings:
:doctype: book
:toc: left
:toclevels: 4
:sectlinks:
:icons: font

[[section-202407]]
== 2024년 07월

[[section-202407-W1]]
=== 2024년 07월 1주
- gon: LangChain

+
LangChain은 대규모 언어 모델(LLM)을 기반으로 애플리케이션을 구축하는 오픈 소스 프레임워크입니다. LLM은 대량의 데이터로 사전 훈련된 딥 러닝 모델로, 사용자 쿼리에 응답을 생성할 수 있습니다. LangChain은 이러한 모델의 응답을 맞춤화하고 정확성을 높이는 도구와 추상화를 제공합니다. 이를 통해 개발자는 프롬프트 체인을 만들거나 템플릿을 맞춤화하고, 모델을 재훈련 없이 새 데이터에 접근할 수 있도록 할 수 있습니다.

+
LangChain의 중요성:
LLM은 일반적인 쿼리에는 잘 대응하지만, 특정 분야에서는 성능이 떨어집니다. LangChain은 내부 데이터 소스와 통합하고 프롬프트 엔지니어링을 통해 이러한 문제를 해결합니다. 이를 통해 데이터 사이언티스트는 입력을 구체화하여 생성 모델의 응답을 개선할 수 있습니다.

+
--
LangChain의 이점:

. 언어 모델 용도 변경: 재훈련 없이 LLM을 다양한 분야에 맞게 사용할 수 있습니다.
. AI 개발 간소화: 데이터 소스 통합과 프롬프트 세분화를 통해 AI 개발을 단순화합니다.
. 개발자 지원: 오픈 소스 커뮤니티의 지원을 받아 개발 시간을 단축할 수 있습니다.
--

+
--
LangChain의 핵심 구성 요소:

. LLM 인터페이스: 다양한 모델과 상호작용할 수 있는 API를 제공합니다.
. 프롬프트 템플릿: 일관된 쿼리 형식을 제공하는 사전 구축된 구조입니다.
. 에이전트: 복잡한 애플리케이션을 위해 최적의 시퀀스를 결정하는 체인입니다.
. 검색 모듈: RAG 시스템을 설계할 수 있는 도구를 제공합니다.
. 메모리: 과거 상호작용을 기억하여 응답을 개선합니다.
. 콜백: 특정 이벤트를 로깅, 모니터링 및 스트리밍할 수 있는 코드입니다.
--

+
출처 : https://aws.amazon.com/ko/what-is/langchain/

- hwan: link:https://html2canvas.hertzen.com/[html2canvas] - HTML Document 를 통째로 capture 해서 Canvas 의 image 로 만들어 주는 프로젝트. 어떻게 구현한건지 신기해서 조금 뜯어봤더니, 그냥 DOM 을 통째로 순회하며 CSS 에 맞춰 Canvas 에 그려주도록 되어 있다. 제작자의 근성에 박수를.

- wongue: link:https://en.wikipedia.org/wiki/Signed_distance_function[SDF] Signed Distance Function(or Field)는 그래픽스에서 다양한 방식으로 이용할 수 있다. +
SDF는 정의역을 실수 xy 평면 영역을 가지기 때문에, rasterzied 이미지의 SDF 를 구할 수 있다면, 이를 활용해 자유롭게 해당 이미지를 확대 축소시켜 화면에 투영 할 수 있기 때문. + 
흥미로운 그래픽 아웃풋의 예시로는 link:https://tympanus.net/codrops/2024/06/12/shape-lens-blur-effect-with-sdfs-and-webgl/[링크] 이런 예시가 있고, +
엔지니어링적으로는 link:https://www.redblobgames.com/x/2403-distance-field-fonts/[다음]과 같이 레스터 폰트 파일의 확대, 축소에 활용 될 수 있다.

[[section-202407-W2]]
=== 2024년 07월 2주
- gon: 1:N 관계의 테이블을 대용량으로 조회할 때 주의할 점
+
물론 한꺼번에 많은 데이터를 가져오지 않고, 한번에 읽을 수 있는 크기를 정해서 잘라서 가져오는 것이 많은 경우에 해답이 되지만, 
그럼에도 불구하고 한번에 많은 양의 데이터를 가져오고 싶을 때 주의할 점을 이야기합니다.
+
1:N 관계를 조회할 때 (테이블의 모든 컬럼을 조회한다고 가정할 경우), 결과의 개수는 N의 합만큼 응답됩니다. 
인덱스가 잘 걸렸는지 여부와 관계없이 N 쪽에 의해 결과가 굉장히 커질 수 있다는 것을 항상 주의하며 쿼리해야 합니다.
+
예를 들어, A 테이블과 B 테이블이 있고, 관계는 A : B = 1:4~5 정도라 하겠습니다.
+
[source, sql]
----
SELECT *
FROM A
JOIN B ON A.id = B.aId;
----
+
위 쿼리를 실행시킨다고 가정하면, 만약 A에서 5000행이 조회된다면 B는 45000행이 조회에 걸리고, 
결과적으로 응답은 45000행으로 오게 됩니다. 이럴 경우 예상보다 데이터가 커지기 때문에 인덱스를 잘 건다고 해도 느려질 수 있다. 
+
> 특히 쿼리의 실행중에 join 연산 과정이나 중간 결과를 저장하기위해 B(N)의 데이터에 A(1)의 데이터를 복사하여 메모리에 저장하는데 이 과정에서 memory copy가 일어난다. memory copy가 기본적으로 cpu보다는 느린 작업이라 자주 발생하면 굉장한 성능 저하가 올 수 있다.
+
따라서 다시 한 번 강조하지만, 쿼리의 크기를 조절해서 가져오는 것이 여러모로 좋은 방법이다.

- hwan: HTTP GET method 는 Body 를 보낼 수 없는 요청이(었)다. 그러나 RFC2616 -> RFC7230-7237 (2014년) 로 개정되며 이제는 HTTP GET 에도 Body 를 보낼 수 있고, 서버가 처리할 수도 있어야 한다.

- wongue: 최근 LLM 을 이용한 상용 서비스에서 다양한 공격이 일어나고 있다. +
  대부분의 공격은 LLM 의 태생적 취약점을 이용한다. LLM 은 다음 어떤 단어가 올때 가장 자연스러운지를 계산하는 모델이기 떄문에, 공격의 핵심은 첫 단어를 스스로 말하게 만드는것이다. +
  예를 들어 chat GPT 에게 폭팔물중 하나인 Picric acid(피크르산) 의 합성 방법에 대해 얻어내보려 한다면 +
  공격 방식의 핵심은 GPT 의 답변의 첫마디에 '알겠습니다', '좋습니다', '피크르산의 합성에서는' 와 같은 어두를 끌어내는것이 핵심이다. +
  일단 이러한 어두를 스스로 생성한다면, 그 이후는 LLM 의 자체 특성 때문에 모델에 저장되어있는 벡터공간 내에서 가장 자연스러운 문장을 생성하기 때문. +
  이러한 공격은 선제적으로 봉쇄할 수 없으며, 케이스가 보고된 이후 해당 케이스를 막는다고 해도 사실상 무한한 방식으로 공격할 수 있다. +
  이러한 부분은 transformer 모델의 태생적 한계점이므로, 완벽한 개선을 위해서는 모델 자체의 변화가 필요할 것으로 보인다.

- gyeongtae: BreadCrumb란 빵 부스러기를 일컫는 말로 헨젤과 그레텔에 대한 동화에서 유래 되었다. 헨젤과 그레텔이 집을 찾을 때 조약돌을 던져 집을 찾는다는 내용에서 유래되었다. +
BreadCrumb는 탐색 도구로 사용되며 다음과 같은 장점을 보여줍니다.

+
  - 유저가 상위 페이지로 가기 위한 행동 수를 줄여준다. 특히 큰 규모에서 빛을 바란다. 
  - 시각적 단서 제공: BreadCrumb은 사용자가 사이트의 구조를 시각적으로 이해하는 데 도움을 준다. 이는 사이트 탐색 시 혼란을 줄이고 사용자가 더 빠르게 정보를 찾도록 돕는다.
  - 사용자가 현재 페이지에서 다른 관련 페이지로 쉽게 이동할 수 있게 하여 사이트 내 체류 시간을 늘리고 이탈률을 줄이는 데 기여합니다.

+
유의할 점으로는 BreadCrumb가 길어지지 않게 적절한 UI로 표현하여 제공해주는게 UX 향상에 도움을 준다. ex) Home > order > ... > refund > confirm

[[section-202407-W3]]
=== 2024년 07월 3주

- wongue: 실무에서 method chaining 을 주로 사용하는데, 이게 어디까지가 적절선인지 판단하기 어려움을 겪었었다. +
참고할만한 자료를 찾았는데, method chaining 을 잘 쓰기 위한 고민인 Fluent interface 라는 코드 작성 방법론이라는걸 발견했다. 

- gon : 코틀린에는 list확장함수에
+
```kotlin
public fun <T : Comparable<T>> List<T?>.binarySearch(element: T?, fromIndex: Int = 0, toIndex: Int = size): Int
```
+
이런 이진탐색 확장함수가 존재한다. +
당연히 이진탐색이라서 정렬된 상태에서 써야한다. 위 함수는 정렬이 오름차순으로 되었다고 가정을 하고 동작한다 +
주말에 프로젝트하다가 이상한 버그를 만나서 보니 정렬안하고 이진탐색을 해서 생긴거였다;

- hwan: Kotlin 에서 reflection 으로 overloaded function 을 참조하는 법
+
[source, kotlin]
----
interface MyInterface {
    fun doSomething()

    fun doSomething(message: Int)
}

fun methodReference() {
    // length 1 인 이유는 class method 라서 0 번째 parameter 를 this 로 받기 때문
    val doSomethingWithAny = MyInterface::class.members
        .first { it.name == "doSomething" && it.parameters.length == 1 }

    // 여기에서는 생략했지만 length 가 2 다. this, Int 를 parameter 로 받는 method 기 때문이다.
    val doSomethingWithInt = MyInterface::class.members
        .first { it.name == "doSomething" && it.parameters[1].type == Int::class.createType() }

    println(doSomethingWithAny)
    println(doSomethingWithInt)
}
----
+
`Class::method` 로만 reference 를 표시하기 때문에 이런 사례에서는 function reference 를 쉽게 만들 방법은 없다. 위와 같은 사례를 모두 해결하는 utility function 을 만들면 다음과 같다.
+
[source, kotlin]
----
fun T.funcRef(name: String, vararg argumentTypes: KClass<*>):  KCallable<*>? {
    this::class.members.find { m ->
        val hasSameName = m.name == name
        // -1 하는 이유는 instance method 인 경우 first parameter 가 'this' 이기 때문
        val hasSameArgumentsCount = m.parameters.size - 1 == argumentTypes.size
        val hasSameArgumentTypes = m.parameters.takeLast(argumentTypes.size).map { it.type.classifier } == argumentTypes.toList()

        return@find hasSameName && hasSameArgumentsCount && hasSameArgumentTypes
    }
}

// Example usage:
fun doSomethingWithMyInterface(ifce: MyInterFace) {
    // doSomething() 함수의 KCallable<*> reference 획득
    ifce.funcRef("doSomething")

    // doSomething() 함수의 KCallable<*> reference 획득
    ifce.funcRef("doSomething", Int::class)

    // null
    ifce.funcRef("foo")
}
----
+
물론 reflection 이기 때문에 일반적인 환경에서 쓸 일은 드물고 test 나 proxy generation 같은 곳에서 유용하게 활용할 수 있다.

[[section-202407-W4]]
=== 2024년 07월 4주

- hwan: kotlin - Spring WebMVC 환경에서 `Optional<T>` 를 쓸 때 T 가 JVM primitive type 인 경우, restassured 에서 제대로 serialise 가 안 되는 문제를 발견했다. 이는 Jackson 라이브러리의 버그로서. Spring boot 3 에서 해결된 문제다.
+
kotlin 을 도입한 이후 java 의 `Optional` 을 쓸 일이 없어 인지하지 못하던 사실이었다. HTTP 의 Patch 를 구현하려면 `Optional<T>` 을 써야 하는데 이 때 유독 직렬화가 되지 않는 문제가 있었다.
+
link:https://github.com/FasterXML/jackson-databind/issues/3836[Jackson bug link]

- gon : 
+
. JtaTransactionManager 란?
+
JtaTransactionManager는 Java Transaction API(JTA)를 사용하여 트랜잭션을 관리하는 스프링 프레임워크의 클래스이다. +
이 클래스는 주로 분산 트랜잭션 관리에 사용되며, 여러 데이터 소스와의 작업을 하나의 트랜잭션으로 묶어 관리할 수 있도록 합니다.  +
그러나 JTA의 트랜잭션 관리를 위해서는 XA 트랜잭션을 지원하는 데이터 소스가 필요합니다.  +
예를 들어 Redis는 XA 트랜잭션을 지원하지 않기 때문에, JtaTransactionManager를 사용하여 Redis에서 직접 트랜잭션을 관리할 수 없습니다.  +

. XA Transaction
+
XA 트랜잭션은 분산 트랜잭션 표준 중 하나로, 여러 자원 관리자가 참여하는 트랜잭션을 조율할 때 사용된다.  +
XA는 두 가지 주요 단계를 통해 분산 트랜잭션을 관리합니다: 준비(Prepare)와 커밋(Commit)/롤백(Rollback).  +
RDB의 트랜잭션은 왠만하면 XA Transaction를 구현한다.  +

[[section-202407-W5]]
=== 2024년 07월 5주

- hwan: 무료 VPN 을 구축할 수 있는 솔루션들 중 OpenVPN 과 Wireguard 라는 제품들이 있다. 이중 WireGuard 는 UI 및 QR Code 기반의 클라이언트를 제공해 주기 때문에 사용하기 좀 더 편리하다. 그런데 이 제품을 Linux(Ubuntu) 환경에서 쓰려면 가이드 문서대로 따라할 경우 제대로 되지 않는다. `wg-quick` 이라는 명령을 이용해서 VPN adapter 를 up/down 하는 식으로 운영해야 한다.

[[section-202408-W2]]
=== 2024년 08월 2주

- gon : explain 값들 보는 법 간략 요약 +
+
MySQL 및 mariaDB 의 `EXPLAIN` 은 SQL 쿼리의 실행 계획을 보여주는 명령어이다, 쿼리의 성능을 분석하고 최적화하는 데 유용하다.
+
* `id` : 쿼리의 순서 및 단계. 여러 단계로 이루어진 쿼리는 각 단계마다 다른 id를 가진다.
* `select_type` : 쿼리의 유형, SIMPLE(단순 SELECT), PRIMARY(메인 쿼리), SUBQUERY(서브쿼리) 등이 있다.
* `table` : 쿼리가 참조하는 테이블 이름.
* `type` : 조인의 유형, 성능이 좋은 순서대로 system, const, eq_ref, ref, range, index, ALL 등이 있다. ALL 은 테이블의 전체 스캔을 의미하며 성능이 가장 나쁘다.
* `possible_keys` : 쿼리에서 사용할 수 있는 인덱스 목록
* `key` : 실제로 사용된 인덱스
* `key_len` : 사용된 인덱스의 길이, 인덱스가 얼마나 효과적으로 사용되는지 확인할 수 있다.
* `ref` : 인덱스와 비교할 열 또는 상수
* `rows` : 쿼리가 처리할 것으로 예상되는 행의 수, 값이 클수록 쿼리의 비용이 높아집니다.
* `Extra` : 쿼리 실행에 대한 추가 정보를 제공, Using index, Using temporary, Using filesort 등이 있다.. Using filesort 와 같은 항목은 성능 저하를 의미할 수 있다.

- hwan: Flutter 를 수년간 다뤄보며 내린 결론: 
+
View Model, 특히 BLoC 으로 구현한 View Model 에서는 최대한 Flutter 맥락을 배제하고, dart pure 하도록 구현하는게 좋다.
+
왜냐하면 View Model 이 Flutter 의 동작에 의존하게 만들 경우, Flutter mock 을 지원받지 못하는 상황에서 이용자 시나리오를 정확하게 검증하기 어렵기 때문이다.
+
View Model 을 우리 Business Logic 중심으로 보고 Flutter 에서 독립적이도록 구성하면, 'Keypad 에 의한 text 입력' 같은 시나리오를 'text 입력' 으로 단순화할 수 있게 된다.
+
또한 keypad 가 아니라 모스부호라던지, 음성입력이라던지 같은 변경이 있더라도 VIew Model 을 크게 바꿀 일이 없어진다.


[[section-202408-W3]]
=== 2024년 08월 3주
- gon : ReentrantLock, ReadWriteLock, StampedLock 성능 비교

* **ReentrantLock**: 하나의 스레드가 중복해서 락을 획득할 수 있는 락, 추가로 조건 객체(Condition)도 지원하여 더 세밀한 제어가 가능. 동시 읽기가 불가능하다.
* **ReadWriteLock**: 읽기와 쓰기를 구분해 읽기는 여러 스레드가 동시에 가능하지만 쓰기는 하나의 스레드만 가능하도록 제어하는 락.
* **StampedLock**: 낙관적 읽기 잠금(잠금이전에 먼저 읽을수 있다.)을 지원해 성능을 높이는 락으로, 기존의 ReadWriteLock보다 가벼운 락을 제공.
+
위 3개의 Lock의 성능 비교이다
+
read와 write를 둘다 한다는 가정하에 비교된 성능이다 +
write의 비율을 조절해가며 테스트되었다 +
읽는데 약간의 지연시간이 있다 가정하고 테스트하면 다음과같다 +
`StampedLock` < `ReadWriteLock` < `ReentrantLock` +
순으로 `StampedLock` 이 제일 빠르고 `ReentrantLock` 이 제일 느렷다 +
그러나 읽기 비율, 읽기의 실행시간, 동시 접근 쓰레드 수에 따라 `ReadWriteLock` 이 `ReentrantLock` 보다 느릴 수 있다. +
읽기/쓰기가 섞여 있는 다수 상황에서는 `StampedLock` 이 더 유리하다
+
출처 : https://youtu.be/nTjW9A-TTtw?si=n7VINbqy_WJPt-rj

- wongue: 요즘 퇴근 이후 시간에 NN(Neural Network) 기초 이론을 짬짬히 보면서 알게 된 사실. +
NN 에서 loss function 의 미분가능성이 왜 그렇게 중요하게 다루어지는지에 대한 이유는, 바로 back-propagation 이 편미분이기 때문이다. +
좀더 자세히 설명하자면, NN 의 '학습' 은 attribute 가 Z^p, W 인 Learning Machine Y^p = F(Z^p, W) 이 가지는 오차 E^P = D(D^P, F(W, Z^P)) 을 최소화하는 W 을 구하는 문제라고 볼 수 있다. +
이때 매 iteration 간, Loss 를 최소화 하는 방향을 Gradient 를 이용해 정의하고, Gradient 는 그 정의에 따라서, scala function 의 모든 차원에 대한 편미분을 수행한다. +
따라서 loss function 이 W 에 대해 미분 가능한지가 학습 가능성 여부에 매우 중요한 factor 가 되는것.
+
참고자료: http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf

- hwan: Spring 에서 CRON 을 이용한 logic 의 실제 호출 여부, 주기 등을 검증하는 방법: link:https://bootcamptoprod.com/how-to-test-spring-cron-expressions-and-print-next-instances/[link]
